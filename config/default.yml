# Parameters to setup experiment.
experiment:
  # Unique experiment identifier
  id: lego
  # Experiment logs will be stored at "logdir"/"id"
  logdir: logs
  # Seed for random number generators (for repeatability).
  random_seed: 42

# Dataset parameters.
dataset:
  # Type of dataset (Blender vs LLFF vs DeepVoxels vs something else)
  type: blender
  # Path to dataset.
  path: data/nerf_synthetic/lego
  # Optionally, provide a path to the pre-cached dataset dir. This
  # overrides the other dataset options.
  #cachedir: cache/legocache200
  # For the Blender datasets (synthetic), optionally return images
  # at half the original resolution of 800 x 800, to save space.
  half_res: True
  # Stride (include one per "testskip" images in the dataset).
  testskip: 1
  # Use NDC (normalized device coordinates).
  # Usually False for synthetic (Blender) datasets.
  #ndc: False
  # Near clip plane (clip all depth values closer than this threshold).
  near: 2
  # Far clip plane (clip all depth values farther than this threshold).
  far: 6

# Model parameters.
model:
  # Use viewing directions as input, in addition to the X, Y, Z coordinates.
  use_viewdirs: True
  # Coarse model.
  coarse:
    # Number of layers in the model.
    num_layers: 8
    # Number of neurons in each layer of the MLP
    num_neurons: 256
    # Add a skip connection once in a while
    skip_connections: [4]
    # Whether to include the position (xyz) itself in its positional encoding.
    include_input_xyz: True
    # Whether or not to perform log sampling in the positional encoding of the coordinates.
    # TODO - no support yet (always True)
    #log_sampling_xyz: True
    # Number of encoding functions to use in the positional encoding of the coordinates.
    num_encoding_xyz: 10
    # Number of encoding functions to use in the positional encoding of the direction.
    num_encoding_dir: 4
    # Whether to include the direction itself in its positional encoding.
    include_input_dir: True
    # Whether or not to perform log sampling in the positional encoding of the direction.
    # TODO - no support yet (always True)
    #log_sampling_dir: True
  # Fine model.
  fine:
    # Number of layers in the model.
    num_layers: 8
    # Number of neurons in each layer of the MLP
    num_neurons: 256
    # Add a skip connection once in a while
    skip_connections: [4]
    # Whether to include the position (xyz) itself in its positional encoding.
    include_input_xyz: True
    # Whether or not to perform log sampling in the positional encoding of the coordinates.
    # TODO - no support yet (always True)
    #log_sampling_xyz: True
    # Number of encoding functions to use in the positional encoding of the coordinates.
    num_encoding_xyz: 10
    # Number of encoding functions to use in the positional encoding of the direction.
    num_encoding_dir: 4
    # Whether to include the direction itself in its positional encoding.
    include_input_dir: True
    # Whether or not to perform log sampling in the positional encoding of the direction.
    # TODO - no support yet (always True)
    #log_sampling_dir: True

# Training-specific parameters.
train:
  # Optimizer params.
  optimizer:
    # Name of the torch.optim class used for optimization.
    type: Adam
    # Learning rate.
    lr: 5.0E-3
  # Learning rate schedule.
  #scheduler:
    # Exponentially decay learning rate (in 1000 steps)
    #lr_decay: 250
    # Rate at which to apply this decay.
    #lr_decay_factor: 0.1
  # Number of training iterations.
  #iters: 100000
  iters: 1
  # Number of training iterations after which to checkpoint.
  #save_every: 5000
  # Number of training iterations after which to print progress.
  #print_every: 100
  # Number of random rays to retain from each image.
  # These sampled rays are used for training, and the others are discarded.
  num_random_rays: 1024  # 32 * 32 * 4
  # Size of each chunk (rays are batched into "chunks" and passed through
  # the network)
  chunksize: 8192  # 131072  # 1024 * 32
  # Whether or not to perturb the sampled depth values.
  perturb: True
  # Number of depth samples per ray for the coarse network.
  num_coarse: 64
  # Number of depth samples per ray for the fine network.
  num_fine: 64
  # Whether to render models using a white background.
  white_background: False
  # Standard deviation of noise to be added to the radiance field when
  # performing volume rendering.
  radiance_noise_std: 0.2
  # Sample linearly in disparity space, as opposed to in depth space.
  #lindisp: False
# Validation-specific parameters.
#validation:
  # Number of training iterations after which to validate.
  #validate_every: 100
  # Number of random rays to retain from each image.
  # These sampled rays are used for training, and the others are discarded.
  #chunksize: 131072   # 1024 * 32
  # Whether or not to perturb the sampled depth values.
  #perturb: False
  # Number of depth samples per ray for the coarse network.
  #num_coarse: 64
  # Number of depth samples per ray for the fine network.
  #num_fine: 64
  # Whether to render models using a white background.
  #white_background: False
  # Standard deviation of noise to be added to the radiance field when
  # performing volume rendering.
  #radiance_field_noise_std: 0.
  # Sample linearly in disparity space, as opposed to in depth space.
  #lindisp: False
